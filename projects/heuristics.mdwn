Here are some words about general constraints in projects.

# build vs buy

When should the part be locally built versus when should the part be bought and shipped? Note that there are shipping time constraints.

# prototyping

Every prototype has some resource cost, although the cost per unit may go down because of economies of scale.

Number of protoypes: Cost usually goes up with the number of required protypes or builds. Also, for each bug in the design that you don't catch, you will usually have to build another prototype to see if you can remove that bug.

time per prototype: Each prototype takes a certain amount of time to build. As the time it takes per build increases, the total number of possible builds will decrease.

# manual vs automatization

The cost of automating a task is usually greater than manually doing a task. The one obvious time that automatization makes sense is when the cost of manually executing some task exceeds feasibility and only automatics can feasibly achieve the desired results.

# fail fast

So there's this well-known thing in quality engineering where getting bugs out earlier is easier, and this other well-known thing in programming where doing projects beginning-to-end gives you foresight about kinds of problems that might happen and makes the earlier designs bug-free and more efficient and such.

The right way to think about how projects get completed is as a dependency graph. A useful heuristic here is "How would I prove this is impossible as quickly as possible?".

You want to prove the total task will work even if the subtasks fail, and otherwise abandon it. Then you want to prove each subtask is impossible, and replace it appropriately and re-plan integration as quickly as possible (etc etc). It's not as big a deal to structure things perfectly if you have infinite resources and can parallelize everything, which is how the space shuttle and particle colliders are built.

The big danger is doing the non-failfast steps first with one person. If one component has a major problem, that means one node is unexpectedly big. In practice, people replace that component with another component rather than delay, or engineer around it, or just accept the delay. But the overall delay is not due to delay along a specific path--it's due to multiple delays, some on every critical path.

<pre>
20:45 < za3k> my made-up common wisdom (i swear this is a valid thing to do!) is that you shouldn't expect a single unexpected failure point where something takes longer than expected, because of statistics and critical paths.
20:46 < za3k> rather, there's some inflationary procedure that experts in the field already know
20:46 < za3k> and the combination of all the major subparts works pretty much in the expected way
20:46 < za3k> uh, you might look at what large building construction projects do if there's a lot of cross-discipline integration and it's impossible for any people to understand the whole thing.
20:47 < za3k> integration in general is something small organizations do \*not\* understand, and NASA does
</pre>

# yak shaving

The more distant you are from the original task, the more likely your yak shaving decisions or dependency graph is going to lead to weak links and wrong necessity calculations. Baking an apple pie from scratch is entirely possible as long as you make up reasonable bounds for what "from scratch" means; otherwise you'll end up investigating high energy particle physics for how to create new universes for your scratch-built apple pie which is not usually what people mean when they say "from scratch".

Yak shaving is doing all the stuff you have to do before you can do the task you were assigned. These tasks may look unnecessary, but they are in fact necessary. The unnecessary tasks that resemble yak shaving are simply unnecessary and wrong. Instead of calling wrong necessity calculation links "yak shaving", call them junk dependencies or unnecessary dependencies.

# transaction costs

"The people pushing micropayments believe that the dollar cost of goods is the thing most responsible for deflecting readers from buying content, and that a reduction in price to micropayment levels will allow creators to begin charging for their work without deflecting readers. This strategy doesn't work, because the act of buying anything, even if the price is very small, creates what Nick Szabo calls mental transaction costs, the energy required to decide whether something is worth buying or not, regardless of price. The only business model that delivers money from sender to receiver with no mental transaction costs is theft, and in many ways, theft is the unspoken inspiration for micropayment systems. Like the salami slicing exploit in computer crime, micropayment believers imagine that such tiny amounts of money can be extracted from the user that they will not notice, while the overall volume will cause these payments to add up to something significant for the recipient. But of course the users do notice, because they are being asked to buy something. Mental transaction costs create a minimum level of inconvenience that cannot be removed simply by lowering the dollar cost of goods."

* <http://p2pfoundation.net/Mental_Transaction_Costs>
* <http://shirky.com/writings/fame_vs_fortune.html>

See [The Mental Accounting Barrier to Micropayments (Nick Szabo)](http://szabo.best.vwh.net/micropayments.html). "Here I present briefly a theory of price granularity based on a subjectivist view of prices. The function of prices, from the point of view of a shopper, is to let the shopper map his personal resources (budget) to his personal values (unique and not directly observable). This mental process requires comparison of the purchase price of a good to its personal value. This entails a significant mental cost, which sets the most basic lower bounds on transaction costs. For example, comparing the personal value of a large, diverse set of low-priced goods might require a mental expenditure greater than the prices of those goods (where mental expenditure may be measurable as the opportunity costs of not engaging in mental labor for wages, or of not shopping for a fewer number of more comparable goods with lower mental accounting costs). In this case it makes sense to put the goods together into bundles with a higher price and an initutive synergy, until the mental accounting costs of shoppers are sufficiently low. These mental accounting costs, not the physical or computational or amortized R&D costs of payment or billing method, set the main lower bound on price granularity. Judging from pricing granularity trends such as the trend towards flat rates in online services, online pricing granularity is far above suggested micropayment levels of a few cents or even fractions of a cent. The mental accounting costs for a typical on-line consumer seem to be somewhat higher than those in more familiar areas of commerce.
