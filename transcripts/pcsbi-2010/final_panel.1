
>> Let me invite Dr. Kaebnick and Dr. Buchanan to come to the table. We're not going to take a break. We're hardly going to breathe as we move into the fourth and final panel of the day. As they are getting in place, the fourth panel deals very specifically with ethical issues of synthetic biology. Our commission is, of course, ultimately charged with looking at these ethical implications so we have two different panels of speakers, one today and the first one tomorrow to help us focus on these issues. We have asked the speakers of today's ethics panel to tell us what they consider to be the most important ethical issues raised by current and foreseeable developments in the field, to help us understand if we have already or how much we are in danger of crossing any ethical boundaries owing to the unique methods and applications associated with synthetic biology and not common perhaps to other scientific endeavors. Welcome to both of you. And our first speaker will be Dr. Gregory Kaebnick, a research center at the Hastings Center, coinvestigator in a research project on ethical issues in synthetic biology funded by the Alfred P. Sloan foundation. Dr. Kaebnick, welcome. There's only room for so many words in my brain, unfortunately. It's really great to have you here. Look forward to your presentation.

>> Thank you very much for inviting me here. It's a big honor to be here. So my goal, my charge, as I understand it, is to set the table for these next two sessions in these two meetings by giving you an overview and also comment on how these issues might translate into a governmental response. And I should say both by way of giving credit where its due and by way of offering a kind of caveat, that what I'm going to say is informed by and comes out of this Sloan-funded project you mentioned. But it's not anything like a consensus statement of that body. We have brought together a lot of people and I have benefited from a lot of input. I'm certain that not everyone would participate and sign on to what I'm going to say here today. Anything I say that is particularly silly is very much my own. So I group ethical issues raised by syn biointo two categories that perhaps runs counter to one of the premises of this session essentially. One of these has to do with whether synthesizing organisms is bad in itself, intrinsically bad aside from the consequences for human welfare. But the other set of ethical issues does have to do with these consequences. When I talk about the ethical issues, I mean to have both on the table. The harms and benefits as well as the intrinsic concerns. I'll start with the intrinsic concerns which is what our work at the Hastings Center has to date focused on. I believe these come in related, but different forms. And there are related, but somewhat different things to say about each of them. First off, maybe the classic way of articulating concerns about synthetic biology suggests a kind of religious or metaphysical claim. One might worry, for example, that synthetic biology puts scientists in the role in the COSMOS that would be properly held by God. Scientists are playing God is a phrase we have seen over and over again on TV about this. Or slightly different point, one might hold that synbio has an inappropriate degradation of life. Prince Charles seems to have something like this in mind when he lamented that biotechnology was leading to the industrial of life in a capital element. My guess, though is that people mostly don't view the question of what humans may do to life as sort of this single uni tarry. Sacredness might be attributed to some but not all living things and synthetic biology in its current form, though we have heard a little bit and there's been some in the media but getting human reproduction under control, synbio is what we can do with microbes. If you did object to synbio along these lines, it would turn out to have fairly limited force in the public sphere. It's an objection that cannot be fully articulated without appealing to one's faith or world view. Not everyone will share that world view. In fact, we know from one of the readings sent around for this meeting, not everyone would share the objection within the faith of world view. Some will celebrate science as an aspect of human creativity that we are meant to develop and put to use. Finally, there is also an important question whether this kind of concern may legitimately ground public policy in a liberal society. Governments in liberal societies are widely thought to have to maintain some level, some kind of neutrality concerning religious belief. They shouldn't be forced to believe. If I can just offer a little side note here. Some thought the NOI in May that a synthetic cell had been created established once and for all some of the religious world views are false. They climb science that is finally definitively shown that life is just a well organized puddle of chemicals. There's no greater being, no spiritual core and no vital essence by which life is sacred. I don't really see how that reasoning goes. I don't think that's quite right. Seems to me if there's a god who gives microbes, even microbes, some special vital essence, it would be well within that God's powers to endow a synthetic microbe with vital essence as well. A somewhat similar question came before one of the predecessors to this commission, the national bioethics advisory commission. Whether people created through cloning would have souls. Submit that it's extremely difficult to resist the conclusion that they would. And by analogy, it seems that microbes created in the lab would have whatever special soul-like properties there are that characterize microbes generally. Another way to develop intrinsic observations to synbio would be to couch them not at metaphysical claims but as concerns that the field somehow conflicts with important moral conflicts. A number of commentators have suggested that synthetic biology my conflict with the concepts of human agency and life and maybe it promotes a kind of grandiosity about human powers or dismissiveness about the specialness of life. These are sort of low-key versions of the metaphysical claim of human beings in the cosmos of life and what some may see as grandiosity some may see as commendable inventiveness and desirable industry. Also the fact that an organism has been created in the lab doesn't necessarily settle what its moral value is. This also was a point offered in the readings. And finally, again, synbio is still about life and deeply implicated by what we do, as long as we're just doing it with microbes. Another more promising way of saying that synbio conflicts with shared moral concepts to hold it raises questions about the human treatment of nature. To see it is an environmentalist concern. A goal of environmentalism isn't just to make nature a safe place for human beings but to make nature safe to some degree from human beings. We should treat the natural world with the kind of acceptance or even reverence and that seems to saving endangered species or wildernesses and forests and so on. Maybe synbio doesn't square quite with this value. The obvious rejoinedder is that human beings have been altering nature throughout history so the issue has got to be at the very least where to draw the line, even determined preservationists will accept that there's some sort of balance to be struck between protecting trees and harvesting them, so there might also be a balance when it comes to biotechnology. Furthermore, many, at least of the nearer term, potential synbio applications are fairly limited from an environmental standpoint and could be if they worked out right. In many cases, we're not talking about intentional ecological changes. We're talking about creating limited microbes to be contained in a laboratory or factory and would maybe partially displace the petro chemical industry. The classic concerns about the human relationship to nature are about environmental destruction. The demolition of species in wildernesses. Part of the promise any way of synbio is that it will be beneficial to the environment. If that can be achieved and note the conditional obviously, many environmental Is might find at least some applications of synbio aattractive. And I mean this actually from the standpoint of intrinsic values. The kind of deliberate release into the environment that professor Snow was talking about would be another category of protection. So my concluding thought about the intrinsic concerns, I take them very seriously. I'm not inclined to write them off at the outset as illegitimate, as many people with my kind of degree are. But I think that once we study them, they don't point toward a need to restrict synthetic biology. Not now anyway. It seems possible that the intrinsic considerations would change as the details change. If environmental damage looked to be likely or if we began to apply the technology to complex organisms. The second category has to do about the consequences. I'm not going to talk about what these are in any details. So these are more economy at that than I. I want to say a little bit more about the process of assessing them, a conversation that was begun in the last session about professor King. An overarching point I want to make, there was a legitimate question whether current strategies for evaluating possible outcomes are actually up to the task. As has been stressed especially in the last session, the potential benefits and risks of synbio are particularly difficult to assess. It's very easy to be dazzled by futuristic stories of how technology is going to remake the world for the better. It's hard to think hard about the kinds of risks, kinds of potential harms that synbio presents. Some of these appear to me to be very low probability, but very high impact, which is a confounding for us. We blow risks out of proportion. We also weigh them too lightly as happened to very bad effect in the Gulf of Mexico, nor is it clear as many have stressed now how much we can learn about it the risks of synbio with older biotechnologies. Synbio is on a continuum with older work which can be seen as a form of the older work and significant advance on it. And frankly, the testimony at the house energy and commerce committee on this point in May tended to make both these points, emphasizing the respect in advance when discussing the benefits and the familiarity when discussing the harms. Second, we have to negotiate this tension between benefits and harms, sort these out, just as their a debate going on about how to assess technologies, how to weigh benefits and harms. This debate is basically over the approach known as risk assessment and cost benefit analysis on one hand and the precautionary principle on the other hand. One side favors objective scientific and economic analyses, tends to down play the enormive assumptions it makes as when applying a discount rate to future risks and

benefits. And according to its critics anyway, it gives too much weight to potential benefits. The other side invokes an expressly enormive stance and according to critics gives too much weight to potential harms. The point I want to make, there are at issue here a series of difficult questions about values and how to operationalize them and it's easy to bury these decisions and equations without really attending to them carefully. I think a good public assessment of synthetic biology ought to be ex-ples it -- explicit to these and open to reassessing them. So in conclusion, I think a case can be made for pushing the field forward. I think there's also reason for caution. I think we should guard against overconfidence in looking at the outcomes. And I'd offer four general recommendations. I think we need much more careful study of the emergent possibility and the impact of the potential harms. I think we need a strategy that is grounded in good science, is flexible enough to look for the unexpected. I think we need a strategy for studying the risks that brings together different disciplines and different perspectives on the risks. And I'd add that is clearer about the enormive assumptions at stake. And then it seems to me that then we need to go on and on the basis of that conduct an analysis of whether our current regulatory framework is adequate to deal with these risks and how that framework should be augmented. And, of course, the sessions tomorrow will carry that forward. Thank you.

>> Thank you so much. Our second speaker is Dr. Allen Buchanan who is Duke's university distinguished Professor of Philosophy and investigator for the university's Institute for Genome Science and policy. He's also a distinguished research associate at the Uehiro Centre for practical ethics at the University of Oxford. He's worked on or been consultant to past bioethics commissions. He's a veteran.

>> Very happy to be here but I haven't been equipped with any means of changing the slides.

>> We would like to remedy that.

>> It's going to be a problem.

>> In the meantime.

>> There ya go.

>> I'm having a feeling of deja vu. 28 years ago, I was working on the first president's on genetic testing and the other on splicing life, genetic engineering with human beings. In a moment, I'm going to explain why I'm a little depressed because I think some of the language used in the debate about synthetic biology is depressingly similar to some of the language used 28 years ago. I think we need to get beyond that language and the prime suspect here is talk about playing God as Dr. Cade knick has pointed out. There's lots of better ways of talking about the risk of unintended consequences and the risk of overreaching our knowledge than using these slogans like playing God.

I'll say we a number of times during this presentation. It's because I'm presenting work that was done by myself and Russell Powell who is actually at the back of the room here. An earlier speaker said that he was wearing a button that said it's the bioeconomy stupid something to remind him of that. And I'll wearing a tie that depects the anthrax pathogen to remind me of a point that will come up later on.

[LAUGHTER]

Well, let's see. What should the commission do? Well, obviously, we should consider the benefits. And this seems like a no-brainer. But I think that with some past Presidential Commissions, including the last one, there really hasn't been a sympathetic enough explanation to the public of what the full range of potential benefits of new technologies has been. And this sort of stacks the deck because people are very aware of possible risk, but the potential social benefits of synthetic biology need to be thoroughly explored, both in terms of advances in basic sciences and in practical applications. And this last item on the list there is something that's come up a couple of times. Namely, it's important to determine which benefits can only be obtained or only be obtained at reasonable costs through synthetic biology. Because I think that's going to be very relevant to trying to weigh risk and potential benefits. There needs to be a classification of the risks. It's not productivive to talk about the risks in the blanket clumping way. The comprehensive classification needs to try to distinguish the severity of harm, probability of occurrence and immunability to management of the risk and in particular to try to determine which risks, if any, are peculiar to synthetic biology. And it's been suggested earlier today in a couple of talks and comments that there are perhaps peculiar risk of synthetic biology because of the technology is so easily accessible and people can order nucleotides and buy gene synthesizer or use the services of one. They can download the information from the Internet. Well, again, I'm not sure that's so different because 28 or 30 years ago, people were saying exactly the same thing about gene splicing. It was incredibly easy. And in one sense, they were right. I'm not convinced that there's an order of magnitude difference with synthetic biology, at this point at least. In tems of ranking the risk, in our judgment, the most are the risk of unintended bad consequences which people talk quite a lot about today and the so-called dual use risk. Now, the other supposed risks have been mentioned by Dr. Kaebnick and they include the so-called playing God idea and in a moment I'll say why I don't think that's a productive way to label that risk. Worry about devaluing life which Dr. Kaebnick also talked about. And the idea of encouraging unwholesome attitudes toward humankind's relationship to nature. Now, there are in fact two dual use problems, not one. First is the one that everybody talks about, the risk of misuse of synthetic biology by bad non-state actors or rogue states. That's very important. But there's also dual use 2. The risk of quote, good governments using synthetic biology, including research and techniques developed in antiterrorism or defensive bioweapons programs for offensive purposes and the risk of so-called bioweapons arms race. I think it's important for the commission to squarely admit this is a risk and also to admit that efforts to reduce the risk of dual use 1 may not be effective for dual use 2, but they may actually exacerbate dual use 2 risks. Let me just mention something to try to bring home this last point. Look, if you have a big antibioterrorism initiative to try to reduce dual use 1, the first effect is you're going to be training a lot more people who are capable of doing bad things with the technology. The second risk is that you may be creating government agencies which will in their function of doing surveillance over new research will be in a position to get hold of that research, use it for their own purposes and restrict everybody else from using it. Now, I mentioned this point at a meeting on antibioterrorism initiatives a few years ago in Baltimore. There was a member of the NSSAB there. And he said, oh, you know, professor Buchanan, I don't mean to be impolite but you're being paranoid about this dual risk 2. I asked him if he had read the president's advisory commission report on human radiation experiments. He said he hadn't. And I suggested that he should read that before he commented further on my paranoid tendencies. I served on a staff commission and a couple of people in the room worked actively on that. And for those of you who aren't familiar, this is a very sad story of pernicious complicity between leading figures in science and the U.S. Government conducting grossly unethical experiments over a period from about 1944 to 1973. And they were people just like you and just like me. So I think dual risk 2 is something we really need to think about and don't just focus on dual risk 1, although dual risk 1 is extremely important. Now, I don't want to try to assess what the risk of bad unintended consequences is. I'll leave that to people who have more technical expertise than I. But I want to suggest that there are good ways of framing that problem and bad ways of framing it. And one bad way of framing it is to rely either explicitly or tacitly on very misleading metaphors about what evolution is like or what nature is like. People talk about the benevolent balance of nature or in President Bush's report biotherapy they likened natural selection or evolution working through natural selection to the work of a master engineer that produces complete, stable, harmonious master products. Now, from the standpoint of evolutionary biology, this is just bunk. This is not what evolution does. It produces Jerry rigged contraptions that respond to short-term design problems with no forethought for what will happen down the line. And at most, it fleetingly proximates biological fitness. Human well-being is not about biological fitness. We have goals in life that are a little more ambitious than maximizing the number of genes we pass on to the next generation. The problem as I see it is that to a large extent, the public and even many members of the bioethics community have a few of nature that's really preDarwinnian. It's a view of nature as this kind of stable, harmonious largely benign thing. And if you have that view, you will automatically stack the deck against any biotechnologies. You will automatically think that the situation is like this. Everything is humming along just fine. The status quo will continue indefinitely, so long as we don't intervene and mess it up. That's simply not true. As Dr. Venter pointed out earlier, we have already intervened in this planet quite a lot. We have created a lot of problems. We're not just individuals who react with preestablished niches. We create niches. We are constantly changing the environment. And we create problems. And some of those problems we may need synthetic biology to cope with. We can't know which and we can't know whether there are other means but we have to keep that open. I'm not making a pitch for let's go to be synthetic biology full throttle, yahoo. Instead, I'm saying it's very important how we think about the status quo. And part of that is how we think about nature or evolution and our relationship to it. And my sense is that this commission could do a huge amount of good by educating the public and the bioethics community with a more accurate scientifically informed view about nature and evolution. Now, another point, in managing the risk -- of course, the idea is to manual, not to eliminate risk. Life is not riskless.

There's no way to eliminate risk. You need to emphasize that risk reduction is costly and often the marginal costs of risk reduction are rising. That is, additional incrementals of reduction of risk may come at great cost, including the opportunity cost of foregoing benefits that you might have. In terms of institutional design, it's very important in thinking about how to develop practices or, as one of the previous speakers said, social technologies for dealing with this biological technology. It's important to think in terms of institutional design and to note how different incentives apply to different individuals depending on their roles and these incentives can lead them to overestimate or underestimate risk and the cost of risk reduction. It's important to develop cautionary rules of thumb and practices that have the following characteristics. They are knowledge sensitive. That is, we should expect them to change as our knowledge changes and our knowledge increases in particular. Our way of approaching risk should encourage relevant knowledge acquisition. It should take the costs of risk reduction seriously. It should have effective provisions for ongoing critical revision of risk assessment and management practices. And it should not rely on a single risk reduction or prevention principle. Especially for het a hetero genus biology. Now, if you want an example of a cautionary heuristic or risk reduction principle that violates all of those, think of the precautionary principle as it's usually formulated. It's not knowledge sensitive. It doesn't encourage knowledge acquisition. In fact, it discourages it. It doesn't count the cost of risk reduction at all. It doesn't recognize that our situations are dynamic. It doesn't have provisions for ongoing critical revision of how it assesses risk. And it commits the fallacy of thinking there's a magic bullet, a single principle for all the hetero genus areas in which risk may arise. Now, a lot of this has already been gone over today so I don't think it's really important. But let me just mention one thing. Some people think -- and I think this is not unreasonable -- that there may be greater risk to synthetic biology because you may be creating a really novel organisms. And so they worry about the sort of virgin population problem in the case of infectious diseases. We don't have resistance because this is really new. On the other hand, I think there are a couple of considerations on the other side that need to be taken into account. One is that in general, dangerous biological agents like pathogens like the anthrax pathogen coevolved with their prey. So if you have something that's really, really different, it may not, as it were, have a purchase on us. It may be a more matter of ships passing in the night. That's another consideration to weigh in. The other is something mentioned a bit earlier also. And that is the very fact that you're creating more novel organisms, starting with more basic building blocks, means that you have in principle the opportunity to design in more safety features. You don't have that with less radical technologies including sort of conventional genetic engineering. You can do some things by regulating expression of genes. But synthetic biology, at least in principle, you have a wider range of opportunities for risk reduction by designing risk reduction factors into the product itself, rather than trying to provide fences and safeguards after it's developed. I think that's worth thinking a lot about. Now, this is something that Dr. Kaebnick mentioned also. And that is in thinking about risk benefit, cost benefit and cost effective analysis, it's very important to recognize both that these are valuable and that what their limitations are. There's been a lot of work on what their limitations are. And I think the commission could do a great deal of good by helping to educate the public about both the usefulness and the limitations on the usefulness of these risk assessment technologies. Also, I think it's very important to point out that taking consequences seriously doesn't mean you're adopting what moral philosophers call a consequentialist moral framework. There's a lot of misleading talk to that effect in some of the bioethics literature that needs to be dispelled as well. I'm not going to go over thereth -- this because I think Dr. Kaebnick did a good job of it. It's two degree indications.

I really think it's the second version that we need to worry about. I'd like to dispense with talk about playing God because it's so ambiguous and misleading. Also I think if you ask people doing this kind of work, whether playing God, they will say they are not playing at anything. They are deadly serious. Now, what about this idea of humankind's relationship to nature? Well, again, I think we need to avoid misleading metaphors about the living world and talk about the wisdom of nature, benevolent balance of nature, master engineer of nature or talk about genetic pollution or breaching species barriers, all these are very loaded terms. And they are not really conducive to a reasonable assessment of the risk. They get in the way of a reasonable assessment of the risk. Here's another example. This last item. Beware of controversial enormative assumptions being smuggled in under the nature or human nature or nature. I have worked a lot in the ethics of enhancing normal human capacities by biotechnologies, biomedical enhancement. And the debate there has been infected by veryishy and prejudicial talk about not interfering with the natural, not destroying human nature.

And all of that talk needs to be translated into more hard-headed concerns about risks and benefits. It doesn't help. I mean anybody who has looked at the sad progress of the concept of human nature over the last several hundred years knows that some of the best minds have said foolish things about what human nature is and isn't. It's a huge ongoing debate. And instead of smuggling in your moral premises under the supposedly neutral heading of a description of what human nature is, it's much better just to confront these moral issues. Again, that has to do with framing. So let me just -- I tried to go even more quickly than the other speakers. And I'm able to do that because so much of what I said has already been covered. Let me just make one last pitch summarizing. I think the two critical issues are the risk of unintended bad consequences and the two -- not the one, but the two dual use risks. And I really would like to see the commission focus on those issues and rather quickly set aside but in a respectful way towards those who still hold these kinds of views what Dr. Kaebnick referred to as the more intrinsic concerns. Let me just -- it may sound a little harsh, the last thing I said. Take the idea of creating life or of, let's say, reductionism. In your briefing book, there was an article by Cho et al. on synthetic biology and ethical and concerns and raised the concern about reductionism. Many people worry that synthetic biology is going to show that life is nothing but a bunch of molecules or something like that. Well, that's a misunderstanding of what reductionism is. There are a number of different senses of reductionism. No matter what you are able to do with synthetic biology, it's not going to tell us that we're not really moral agents. It's not going to tell us that there's no such thing as wrongness and rightness. It's not going to tell us that there's no meaning of life in any sense of the phrase meaning of life that we're interested in. And I think the commission could do a really good job of pointing this out and then moving on. Moving on to the real questions about unintended bad consequences and the two -- not the one, but the two dual use problems. And thinking about what sort of concrete recommendations can be made both to move the handling of the safety considerations forward and to help educate the public how to think about these issues better. And for today, in terms of the safety issues, the concrete issues of reducing the risk of harm, there's a lot that can be done. Commission Farahany has pointed out we need to think in terms of prohibition and in terms of licensing and tracking and surveillance. And as Dr. Venter said, engaging people in certain kinds of synthetic biology work to have institutional affiliations so that there is some kind of oversight and control. This is what we need to do. And we especially need to do this at the international level. Otherwise you'll have unregulated research in countries that aren't going along with an effort to make the technology safe.

>> Allen, I know the commission is dying to ask you a bench of questions.

>> Perfect. Good timing.

>> I do need, John, to make certain that our chair has an opportunity.

>> I'm going to take it that Allen Buchanan -- I have ceded my time to Allen Buchanan. Seriously, I would like to give my fellow commissioners a chance to ask questions. Jim, if you would.

>> John, you're number one.

>> Okay. Again, thank you. The bar was set very high this morning and it just keeps getting higher and higher as we progress through the day. As Amy Gutmann our chair has pointed out again and again, this is a deliberative body. Okay? And that entails that we need to ask questions like, who is going to be invited to the discussion and what sort of weight we will accord to what they say? These words of argument that they give. So both Greg and Allen have alluded, you know -- Greg at the start and Allen at the end, to how we should deal with questions of religious or metaphysical nature. And I just want to press this question a little bit harder because it does raise difficult and really important questions for any sort of deliberative body like our own. So, Greg, the way you put it originally was that you can respect the views of people who believe that this involves playing God and so forth, but we should sort of discount arguments that are based on sort of sectarian, religious views or on, as you put it, various world views. Now, I can easily understand how we should respond if somebody says, well, we should oppose synthetic biology because that's what Jesus would want us to do. Okay? Because that's clearly a kind of argument that not everybody can, you know, agree to. But if you widen the circle of suspect dialogue to include world views, that would include a lot. It may include Francis bacon's notion of teaming nature for human good, which most scientists would be guilty of. John Stewart Mill will have a similar view of science. And it would also I think include sort of deep ecologists who have a world view that views with suspicion sort of monkeying around in nature or, you know, adding synthetic genes to the natural world. So I'd like you to both really sort of circle back over this question a little bit and help us get a grip on exactly what's at stake here and exactly what your position is on this. Okay? In other words, are you saying that, you know, certain sorts of arguments should be ventilated, but not really given a whole lot of credit. Or what's the position?

>> Well, I think that a full range of views should be ventilated. I don't think that the commission should be preventing people from coming to the table to express their views. But if the commission were to recommend to President Obama and President Obama were to decide -- I'm sorry. President Obama were to decide as a basis of deep ecological world view to oppose research into synthetic biology, that would strike me as potentially violating the suggestion that I made. But I don't think that there's going to be -- my thought is that there are certain kinds of -- everyone comes with a world view, but there are certain kinds of moral positions that can be set out in conversation without having to appeal to them. If I tell you that it's wrong to take the human life, you're not going to ask me what my background and my reasoning for that is. You're going to accept it at face value. But if I tell you that it's wrong to fiddle internally with the genome of a microbe, you might do that. And then I would be compelled to say something. And if it turned out that I was basing it on some unique claims about the status of life or some sort of vitalism, I'm not really -- I haven't really sorted out exactly where the lines are going to be. But that's going to be a problem for policy making.

>> Just a quick reply. I think if you together come to a conclusion to make a certain recommendation, you should not water it down in deference to views that you think are false. Now, that doesn't mean that you should sort of go out of your way to try to show up people's views as irrational or somehow inappropriate. But I think you just have to be courageous enough to say, look, in the parts of our documents where we are drawing conclusions about this technology, we're going to call it as we see it. And we will have a full ventilating of a wide range of views. Nobody should be stifled. But that's not the same as saying that you should sort of view your conclusions as having to track the majority view of the public or that they should even reflect some substantial minority of the public's views if you think those views of the public are simply not supportable. Easy for me to say, but I think that's what you should do.

>> So, Dr. Kaebnick, I wanted to press you about your view of the evolutionary claims and the highlight of the arguments developed now are based perhaps on a flawed view of evolutionary and nature claims. I wonder if there's a version of the claim that you might agree with. And that is that it seems like at least with the types of fixes that you refer to in evolution, some quick fixes that are brought together to solve immediate concerns, that the process is a slow one, right. So evolutionary fixes happen over time which allows the rest of the environment to adapt to those fixes potentially as well. In synthetic biology, we may be talking about faster changes. So you're both right in that we can develop much more efficient solutions, but potentially then the impact on the environment may be much greater, such that nature is able to achieve potentially a slower and more balanced approach than sudden, introduction of drastic changes goes.

>> Well, I think there are actually some sudden and drastic changes that occur in nature without human intervention. I guess what I'd like to say is I think that the important thing is to recognize the complexity of evolved organisms and ecosystems. But recognizing that they are complex is quite different from saying that they are optimal and stable. That's the mistake. That's the mistake that people make. When they talk about a master engineer, they are attributing much more competence to evolution. Organisms are always in danger of intervene you prematurely because we don't know enough and don't understand the complexity. That's quite different from saying we shouldn't intervene because it's perfect and stable. A brief quote from Darwin here. What a book a devil's chaplain could write on the blundering low abhor I hadly cruel works of nature Darwin.

>> I'm not saying that you would say organisms are perfect. But I'm wondering if the rate of change is different than the type of organism.

>> It all depends upon whether the rapid changes we might be trying to make through synthetic biology or other means are ones that are likely to have a large impact on a fairly large ecosystem. And that's where all of these questions about containment and reversibility come in, right? And I think that's extremely important, you know.

Those are the technologies you have to think about. Those are the risk reduction technologies that have to be thought about. You have to try to find out from the scientists which of the containment and reversibility techniques already developed in molecular biology and in the traditional genetic engineering are applicable to synthetic biology. Which ones aren't. Which ones have worked in the former case, which ones are problematic and which new ones you need. That seems to me to be the answer. I'm not denying this is a problem. You're right. If you make some profound change in organism that has fairly dense interconnections with a larger ecological sphere, then the recalibration of the rest of the elements of ecology of that may be pretty Rocky. That's true. Thought all the more reason to think about limited, contained kinds of interventions.

>> Thank you.

>> Anita, why don't we have your question? And then in the interest of time, go out to the audience.

>> Thank you. I have two relative quick ones. For Greg, I was interested in the fact that you mentioned religion in connection with the intrinsic value arguments, and not in connection with the consequencialist arguments. Many people of faith coming out of religious traditionals are not just concerned with vague metaphysical respect for nature of the sacred or inappropriately playing God. They are also concerned about social justice and the kinds of issues we heard from the previous panel about the bioeconomy that the potential result from pursuing a synthetic biology. So I just want you to agree with me that --

[LAUGHTER]

>> Done.

>> Okay, great. Then for Allen, my question is a little more complicated. You made the point along the way that maybe we can manage some of the risk involved in synthetic biology by designing in safety, like the suicide gene or something of that nature. It occurs to me that is an often reassuring folk and engineer in safety. But hasn't experience taught us that we have to be a little bit careful there? Because, for example, with fast cars. Oh, we'll just engineer safety into fast cars. But then the corporate guys decide that it's too expensive to put that extra tough bumper on the back of a car so cars aren't as safe as they could be. Or in the data protection field, we all heard for the whole 1990s, we'll just engineer into the Internet privacy proposals. But then it turned out the website guys, they want to create a market of new information and not going to engineer privacy into the Internet.

So we can do it, but whence comes the will to do it? And should the public feel safe that we're in fact going to get those safety devices engineered into the product?

>> You're absolutely right, obviously, saying in principle, looks like there are greater resources for synthetic biology for designing in safety features. That's in principle. What happens in the real world? That depends on what the incentives are and the regive regime can test those limits. I think that's a crucial question. I wouldn't want somebody to overrely on the idea we can design the safety in. It's a combination of sort of external controls and some designing in. And the question is, how can you ensure that the designing in safety really gets done and gets periodically reevaluated and works in a complementary fashion with other kinds of safety measures that have to do with the environment that the product operates in? You mentioned the notion of justice, too. I just want to mention that the slide presentation is just a fragment of a larger piece that Russell Powell and I wrote for the commission that's about seven pages long. And in it, we do spend some considerable time on the justice issues. I'd like to say one thing about that. I don't think there's a peculiar part of justice in synthetic biologies, it's part of innovation. We live in a world in which innovation is very important.

And our theorizing about justice and institutions have to take into account the problems with justice and innovation. For the most part, there really are problems about the slow diffusion of beneficial innovations. Okay? It's that we need to learn how to reduce the gap between when some people get a beneficial innovation and when the bulk of people get it. For some technologies, that gap is very small. Cell phone technology is the best example. Diffusion of cell phones has been quite incredible. Poor peasants in south Asia are revitalizing their economic life with cell phones. The political life of cell phones has been incredible, too. You can't assume a technology is going to diffuse quickly. We need to think about how to speed up the diffusion of beneficial technologies and don't be a synthetic biology exceptionalist and think this is just a problem for this area. The solution to the problem for synthetic biology has to be part of a larger problem of thinking about new practices and institutioning for justice in the diffusion of innovations.

>> Why don't we take one question from the audience? If there is one. With the reminder to others that when we reconvene after this session, we will have a plenary that will involve all of our speakers so we can have more questions. Really just one at this time. I'm sorry. Hang on for the plenary session. Yes, sir.

>> Good afternoon. My name is Sal hajarski and I'm a student.

My question goes back to degrading life and you addressed this and I understood your counter arguments in regard to the subjectivity. But I have to be reminded of something that Mr. Thomas, the previous speaker who was up here, kind of brought up about the economics of the biology industry. What I was really wondering is what you think using life as a means of production would do in terms of devaluing life. I understand we use living things, obviously, as products. We have agriculture, etc. But we haven't really used it in itself as a means of production. I mean to the scale that we would be using biotechnology or synthetic biology, rather. So I was kind of wondering about that.

>> Well, briefly, I'm just a little uncomfortable at talking about using life as a means of production. Life is just too big a term. Okay? If you get more specific, I think most of your concerns will dissipate. Okay? If you are using living things, you said it. We use living things as a means of production all the time. We are a living thing. We use ourselves. So I would worry about this kind of redefining talk of using life or people saying you can't patent life. That's not a very useful entry into the very complicated debate about intellectual properties to say let's don't patent life. Talk specifically about what you're talking about patenting and why you object to it. And talk about which biological processes you think shouldn't be used in which ways for which kinds of production. Be much more comfortable with that kind of talk. I just don't think it's very productive. You are clearly on to something. We don't want to treat everything as if it only had instrumental value. We can all agree on that. We need to get down to particulars, if we're going to get very far with that.

>> Did you want to comment, Greg?

>> No. I think that's exactly right. I think that the concern is a serious one, but I would want to search for distinctions along the way rather than treat all of life --

>> One of the things the commission has learned that in certain sessions, we need to allow a little bit more time. But what we will do is reconvene in just 10 minutes. This is quarter past 4:00. For the plenary session, we have all of our speakers with us and we can engage them in further conversation. Thank you, Dr. Buchanan, thank you, Dr. Kaebnick.

[APPLAUSE]

