William Gunn
http://mendeley.com/

I am the head of academic outreach for Mendeley. I would like to invite anyone to blog and share this presentation. So I am going to talk to you about what we're doing at Mendeley but really what I want to talk about is the perspective of the research process, since I'm from a research background, and moving into a startup environment. I want to share some ideas about how we can help catalyze open science as a movement and how to catalyze effective research.

I was at a meeting with National Academy of Science. How do we get to a cure faster? There is a lot of talk about DARPA as a model for engineering these things to work faster. You know, it struck me that what we're trying to do, study diseases and so on, is way more complicated than engineering a jet engine or something like that. It's a complicated sort of thing that we have to deal with that. Just any kind of innovation is hard. The light bulb, hwo many years did we have the lightbulb before we had this room?

Before I get into this, I want to talk about a story that we should consider. Does anyone recognize this guy? This is Hairy Creamer, he was a business magnet in the 60s who was fascinated about human powered flight. He thought that this could be transformative for the world. He wanted to see this happen. He put up $50k and $100k in the 1960s which made it the xprize of its day. A lot of aeronautics companies worked on prototypes, making them lighter giving the mmore lift, etc. So they would get funding and they would build these prototyeps and test them, and they would crash 50 meters into the ground later. They would then test them a year later. The prize was not won for more than 10 years, even with all these experts in aeronautics until Paul McReary came along. The problem was not how to make our planes light enough for whatever so people ccan fly them, but how do we fix the testing process so that we can engineer this stufff without it being expensive or boring?

So he built these prototypes which were initially just plastic tubing that, wouldn't even fly to begin wtih, they were breaking all the time, but they were so light and cheap that he could tape them back togehter, and he could do 2 or 3 tests per day instead of per year. One of his planes, did it. He won both of the prizes. He's known to be one of the most brilliant engineers in the whole aeronautics industry.

This probably sound sfamiliar in research. There are these large time scales. The publication timescale is huge. The treatment for ATR2-positive breast cancer. The first paper was back in 1994 but you didn't see the activity until after 2000 and such. That's a huge time lag. As you can see, the citations and characteristically are lagging the publications by about two yearsi n this process. Towards the front, it takes a nose dive at 2010. This was data pulled yesterday. There's a huge lag, what's the nature of this impact? The guys who came before me talked about the problems about the system. I wanted to make a good point here.

How do we take all this money, $300 million from the NIH and other mechanisms, and put it in this black box of research. 12 years to get a drug to market? 42 is the average age is where a researcher gets their first NIH grant. At that time, all that buy-in, maybe you don't want to rock the boat at that point. So how do we get a product out there that is tasty sausage and not somthing else that this could be. How do we take that 12 years and make it 12 months?

Here are some ideas. You could look at the papers that get cited, but that takes a long time and it's not fast. You could go for the journal with the most sselective process. But history has shown that you can't pick whih papers will have the most impact, or which ones will be retracted ahead of time. There's actually a pretty good correlation between impact factor and the number of retractions, this is a sign that this process is broken.

Can we get more and better data faster? Let's publishg excessively, will that catalze things? We kicked this off at Mendeley, we wanted to get this real time. To do that, we built a tool, a desktop client that people download and use to organize their research papers. We can aggregate all this catalog, this crowdsourced catalogs with all these signals from the domain experts. We have a fairly good reputation, we have a ton of data to dig into this stuff. All of this data is associated with author profiles in the system, which is a rich social demographic layer. With all this stuff together, we canc ome up with great summaries that will show you the top researchers, the key concepts that you want to dig into, and the breakout papers for the subject.

But, I'm not going to stand here and say using Mendeley is going to help you cure faster. That's not true. It's about using the data we've collected to drive your process faster. There's more stuff to do with this data than there are ways that we could hire developers to do. If Jason, our cofounder was here... we put up a prize to incentivize people to take data and build something ccool. A cool open science project at the end, it was opensnp.org where someone built this platform where you can share your 23andme or decodeme genetic data. It just aggregates all this stuff. All this data is CC licensed, and you can download it and look at correlations, and it has literature search.

Some other people took our data and came up with simple versions of metrics. This is the person index, it's another way of looking at an author's impact. Say you have A sub 4 of 7, if you hae 7 papers on Mendeley.. the difference here is that this is updated on a daily basis, as soon as it comes out it has these metrics accumulating, so it cuts 2 years out of that cycle. As you will see later on, there are other people that are taking this data and making a product out of it. Jason will talk about impact later.

There are people taking this and trying to come up with new peer review models, attaching Mendeley objects to this peer review system. Leverage the systems already existing and don't try to take this overhead to create a peer review system from scratch.

This is another data project- encouraging people to build semantic links between documents. I think it's a neat idea, you know. So we have all this data from all these academics,s o now we are trying to segment that and come up with focused areas. So we have whole institutions as blocks as now, and now we have Mendeley Institution edition. It's like Google Analytics for your research. If you are a library you want to know who at your institution is reading which journals, which are the ones that I really need? It gives them leveraging power against traditional bad deals that the publishing industry forced on them. It's another I guess pressure point within the whole theme there.

If you are a researcher in that institution you might want to know who is reading my paper, in which industries am Ihaving an impact? You can get that stuff out. What major papers are having impact on my department or my colleagues?

So that's what I've talked about- our data and what we've been doing it with. You should build products on top of Mendeley data and help accelerate science. Thank you.



