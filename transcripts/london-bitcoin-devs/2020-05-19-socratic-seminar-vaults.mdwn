2020-05-19

London Bitcoin Devs

Socratic Seminar: Vaults && OP\_CHECKTEMPLATEVERIFY

<https://twitter.com/LDNBitcoinDevs/status/1262768047623790592>

See also \#\#ldnbitcoindevs on freenode IRC.

Victims: max hillebrand, bryan bishop, kevin loaec, michael folkson, spencer hommel, sam abbassi, jeremy rubin, riccardo masuti

MF: We'll get started in about five minutes. I'll say this again. If you're not speaking, can you mute and turn your video off? If we have everyone on video, we might start to have problems in terms of performance. If you're speaking or screen sharing, and you want to show your face, then please do because it makes the video better if people can see the person who is speaking. We just can't have video on all at the same time. I'll turn my video on to do the intro.

MF: This is the Lodon BitDevs socratic seminar. We're livestreaming on youtube. Please be aware of that for the guys and girls on the call. We're using jitsi, which is open-source, free, and doesn't record your data. Check out jitsi if you're interested in doing something similar.

MF: A socratic seminar is something that originated in BitDevs NYC. Some of the people on this call have previously attended them. The emphasis is on interaction, questions, feel free to have discussions that move the topic on to whatever you are interested in. This is not a formal presentation. We have some of the experts on the call.

MF: The topic is vaults and OP\_CHECKTEMPLATEVERIFY. Usually we start with short intros. Introduce yourself. Raise your hand if you want to do an intro. How much do you know about covenants and vaults?

BB: (intro)

MF: Spencer?

SH: My name is Spencer. I am a bitcoin developer at Fidelity Center of Applied Technologies incubator. I have been working on vaults since Summer 2018, working on a hardware solution with pre-signed transactions. I am also working with Bryan Bishop on those manuscripts as well.

MF: Kevin?

KL: I am Kevin Loaec. I'm probably the least technical on this call. I've been interested in covenants and vaults. Not too long ago, my interest was raised with the first proposal that Bryan Bishop sent to the bitcoin-dev mailing list about 7 months ago. I started picking up my interest in this. I've been working on it since December 2019 when a client of ours had a specific need where they wanted a multi-party vault architecture for their hedge fund. That's when I started digging into this and coming up with an architecture. I'm working on a project called re-vault which is a multiparty vault architecture which is different from the one that the other guys here are working on. But it has a lot of similarities and it's going to be an interesting talk today.

MF: Thank you much, Kevin. Max?

MH: I am Max Hillebrand. I'm a user of bitcoin technologies and I contribute to open-source too, mainly a wallet. I've been interested in different property rights definitions that bitcoin script enables, such as multisignature which is what my academic thesis is on, and I also follow the utxos.org site and some of Bryan's transcripts. Just interested in the topic in general. Thank you for organizing this.

MF: Thank you, Max. Anybody else? Jeremy?

JR: Yeah, sure. Hey everyone, I am Jeremy. Thank you for the intro before. You know a little about me. I've been working on bip119 OP\_CHECKTEMPLATEVERIFY which is a new opcode for bitcoin that could enable covenants and smart contracts. One of those use cases is vaults, and I released some code about this on utxos.org where you can see there is a vault implementation and you can check it out. It's based on OP\_CHECKTEMPLATEVERIFY but I'm currently working on better tools to be able to use OP\_CHECKTEMPLATEVERIFY... Can you all hear me? Hopefully this will make it easier for people to implement all kinds of vaults in the future.

MF: Awesome, thanks Jeremy.

SA: My name is Sam. I am working at Fidelity with Bryan and Spencer on vaults. I probably have the least amount of experience with respect to vaults. I'm gaining more exposure to it.

openoms: I am implementing some new services in a full node script collection called restful bits.... in bitcoin and lightning for a few years. Enthusiastic about privacy as well. Don't know a lot about vaults, but I am very enthusiastic and want to learn more. I am looking forward to this conversation.

Swambo: Hi everyone, my name is Jacob and I am working with Bryan and Spencer and Bob McElrath on the vaults manuscript that were mentioned on the bitcoin-dev mailing list not long ago. I am a PhD student at Kings College London and I have been working on this for about 1.5 years. Happy to be here talking about all this.

waxwing: Adam Gibson here. I don't have any specific knowledge about this topic but I'm very interested in it. I'll let you get on with this.

MF: Thank you, Adam. Basic question- this is for the beginners and intermediates. What is a covenant and what is it trying to do?

BM: My name is Bob McElrath. Also working with Bryan, Spencer, Sam and Jacob. Hopefully a draft will appear soon in a week. I have a talk about this topic, last summer in Munich. If you google my name and Munich I have a whole talk about why covenants and going through the various mechanisms.

BM: A covenant is a restriction on where a UTXO can go next. When I sign a UTXO, I provide a signature which proves that I control it and it's mine but I don't have control about where it goes after that. A covenant is some kind of restriction on the following transaction. With that, you can create a vault which says the following transaction has to go to me one way or another. So I separate my wallet into a few pieces, one of which is going to be more secure. When I send between hot and cold, or an active wallet, then it has to go to me. I make a restriction on the transfer of the UTXO which says that if you get into my wallet you can't just sign it-- the covenant enforces that it goes to me. I'm introducing a few layers of complexity into my wallet in order to do that.

MF: Yes, that answers my question. It's a sophisticated answer. I don't know if -- any other beginners or intermediates, did you understand that answer? What are your initial understanding of covenants before this? Any questions for Bob?

waxwing: An open question about this is that it's an obscure name. It doesn't immediately jump out at you what it is. I like the explanation, Bob.

BM: Well, we can blame Emin Gun Sirer. They wrote the paper in 2016 and they named it covenants or vaults.

JR: I know it's fun to blame Emin for this, but the term covenants existed in the bitcoin context before that. The historical reason why is because covenants restrict how property can be used or transferred. In the Bay Area, there is a dark history of covenants which prevented black people from owning property--- like you could sell this house, but not to a black person. When people talk about covenants, there's often weird things in their deeds like you can only ever use this property to house 25 artists. You can't remove the covenants. People didn't like covenants early on-- it's an inherently loaded term. It was used to cast some of this in a negative light. Not just in the bitcoin context or cryptocurrency context, people have a negative association of covenants of someone else controlling your own property. I liked Bob's description: this is really about, in bitcoin, about controlling your own property.

JR: Each bitcoin is like a treasure chest with gold coins and you can open it up and do whatever you want. But imagine you opened up your treasure chest one day, and you find Jimi Hendrix's guitar. Well what would you do with it? It's a sacred thing, so obviously it should go straight to a guitar case. That's what a covenant is doing. It tells you what are safe containers for you to move your item to another area. For the most part, we're still talking about using coins. So if you say hey these are coins but they are made out of uranium, but you have to put them in a led box, which is the safe next step, and so on and so forth. I think that's one of the metaphors that works for covenants. You're able to control the safety and movement of your own coins.

MH: I know that from covenants.... from the incumbent banking system where if you have a loan contract, for example for the bank to have a covenant, the bank can make a requirement that if the company cash flow to equity ratio drops to a certain level then they have to pay it back or renegotiate a contract. It's a limitation on a contract where the contract has to be changed when one of these triggering events occurs. Seeing it as a restriction in bitcoin makes sense. If you have the private keys to a key, then you can spend it, but with the restriction that it must go into a certain address. .... I think the term makes some sense.

MF: Let's move on, we lost the second half of that. I think some of you have seen the pastebin I put together about some of the resources we can talk through. That's on the twitter or meetup page. I'm going to share my screen. The very first link that I linked to is -- and I have a bunch of these links from Jeremy's interview with Chaincode Labs podcast which I think was excellent-- he talked about some of the misery of implementing bitcoin covenants. The first one is a link to an early bitcointalk.org post about how covenants are a bad idea. Maybe we can talk about why people thought bitcoin covenants were bad.

BB: (Greg Maxwell and bitcointalk.org)

JR: Greg has said, "I don't know why everyone thinks covenants are bad. I have never said anything about them being bad." But I said, Greg, everyone I talk to says it's because you said they are wrong in this thread. If you don't think they are bad, then you should make that clear. But he has written that in IRC, that he doesn't have any hangups or--- it's not even recursion that is the problem. It's virality. He doesn't want a covenant system where your coins accidentally get wrapped up into a covenant... maybe recursion is part of that. That was the major concern that Greg was talking about.

MF: There's two elements. One is timing, maybe it was way too early to implement covenants back in 2013. Second, there's perhaps some views on the big ideas of covenants were stupid or too complex back then. Maybe it was a case of batting down the hatches and making sure some crazy ideas didn't get into bitcoin.

BM: Any time you do a covenant--- any agreement you make with a receiver is a private agreement. You can have any terms you want. Greg's post enumerates a bad idea where one party restricts or imposes a restriction against another party against their will. It's not that covenants are a bad idea; if you and I both agree to it, then fine. But for the most part, covenants are the most useful for one-party arrangements not two-parties. When you have a two-party arrangement, everyone needs to understand what's going on. It can't be a regular wallet, the scripts change, and everyone needs to know what's going on.

JR: Hard disagree on that note. One of the major benefits of covenants comes into play with lightning network related things. It dramatically simplifies the protocol and increases the routability by improving the number of HTLCs you can have, and the smart contracts that can live in a lightning channel with reasonable latency.

BM: I think we agree there. If you are using a lightning wallet, then you have agreed to those rules.

JR: I agree there's a huge amount of value in a single-party system, but multiparty things are useful with covenants because the auditability is simpler. You're writing half the amount of code to do some of the setup here.

MF: Any other thoughts on that before we move on? The next couple of links I put up was Aaron Van Wirdum's article on OP\_SECURETHEBAG just after Jeremy's presentation... Then there's this paper by Emin Gun Sirer and Mosser and Iyal.... any thoughts on this paper from 2016? Anyone want to summarize the key findings from this paper?

BM: I can give it a stab. This was the first manuscript in this space. They defined a new opcode that acts like a regular expression that says I'm going to examine your redeemScript and I'm going to impose arbitrary restrictions with a regex on your script. The other thing they defined is recursive covenants, as well as the kind of the protocol where if somebody manages to steal your funds- you can get yourself into a game where--- the entire value of the transaction goes to fees. They claim this is beneficial because the thief can't earn any money. I don't like this aspect; I don't think anyone wants to get into a game where they lose all their money anyway. Those are the broadly the three things in that paper.

BB: Well, it might be useful to not fund an adversary.

BM: You don't have to get yourself into a game where you pay those fees.

waxwing: What exactly was the name of the -- they introduced a new opcode for this? I am looking at the paper now.

JR: They called it OP\_COV. There was a few problems with it. It wasn't just the technical capability that it introduced. The proposal wasn't that secure. There are a few gotchas in it that would make it hard to deploy. I tried to answer that in bip119. And the integration questions like well if you're really signing transactions, what could go wrong? With an unrestrictive design, there's a lot of edge cases.

BB: (2016, soft-fork)

JR: I think they just didn't know it could be done with a soft-fork.

BM: I had a blog post just after that, they missed that. The manuscript doesn't talk about timelocked opcodes correctly. It was published around the time the relative timelock BIPs were deployed and activated in a soft-fork.

MF: I think the next link is Jeremy's talk in 2017 at.... this is Jeremy's presentation at Stanford Blockchain Conference in 2017. This was your first presentation I saw, Jeremy, on covenants. It had a bunch of different use cases and your current thinking back then including some interesting use cases. Of all these use cases, which ones are still of interest now? How has your thinking changed since that presentation?

JR: Hang on a sec. Let me pull up what the...

<https://diyhpl.us/wiki/transcripts/blockchain-protocol-analysis-security-engineering/2017/2017-01-26-jeremy-rubin-covenants/>

<https://rubin.io/public/pdfs/multi-txn-contracts.pdf>

JR: I think a lot of them are still useful. Lightning ... and do the details later, for congestion control. Optical isolated contracts and there's some vault stuff in here too. That stuff is obviously still interesting. Let me find where the vault related things are. In this presentation, I define a bunch of different types of opcodes. One thing I defined here was a tapscript-style thing at the transaction level where if you can have transactions required to be spent within the same block, then you can have scripts that expand out in a series of transactions. In my opinion, that's an interesting primitive because you can have scripts that are required to expand over a number of blocks but they split out how the funds are distributed to each UTXO and you can build out different flows based on that kind of expansion. I think those kinds of things are interesting. I don't think there's anything irrelevant in this presentation- it's just about carving out the small bits that can work safely. One thing that I have been thinking about as a next step for bitcoin after CHECKTEMPLATEVERIFY or an equivalent is that I would like to see an opcode that lets you check how much value you're spending. Say you paste an address to someone, and if it's under 1 BTC then the receiver uses a single key, but if it's over 1 BTC then the receiver has multisig. You could use that as a safety mechanism in a number of applications. I think that's an important thing going forward, which wasn't in my 2017 presentation. It's interesting to think about that for things like contracting in the UTXO model about things that are possible.

MH: Why is this an improvement for congestion control?

JR: I'm happy to, unless someone else wants to jump in. Okay. So, the idea of congestion control is mostly that there's a fundamental amount of traffic that has to happen. There's a peak demand. What you want to do is-- it's like coronavirus, you want to flatten the curve. I was looking at all the diagrams about "flatten the curve" and I was thinking hey that's what I've been working on in bitcoin for the last year. Say it's lunch time and there's 10 MB of transaction data coming in every 10 minutes but only for an hour. Over the rest of the day, those transactions will be clearing. With congestion control, you commit to all those transactions, but you spread out the redemption. You confirm all of them at once, but you spread out the redemption window when someone goes and gets a particular UTXO out of it. If you think about fees as a bidding market, you're bidding simultaneously for confirmation and you're bidding for redemption and this is an inefficient market because that's two different markets. The confirmation price can be shared among a number of markets, and you bid a second price for redemption. Fewer people bid in the first market for confirmations, and more in the redemption market.

MH: One follow-up question. Say I make a transaction that pays 100 users. I get that confirmed at a low fee. Then how does that work with the users redeeming their coins? Does it have to happen for all the 100 users at the same time? Can 10 users do it fast and the other 90 doing it slower?

JR: OP\_CHECKTEMPLATEVERIFY is a general purpose opcode. The answer is whatever your users want. So what happens is that-- we can also talk about mining revenue because I think it's important to talk about that if something is reducing fees. I think it improves mining revenue, actually. So you would bundle up all your 100 users into a single transaction. You'd have a single output, and then you'd create them- you'd probably pay a high fee for that transaction because it has 100 outputs. But a confirmation fee on 1 output is a lot lower. You save money as a user. So what you give your users is essentially is that if they have an old wallet, it looks like an unconfirmed spend. So you could give them some unconfirmed spends, and you can structure those spends as any data structure you want. It's like a tree of some sort. It's a linked list of a tree. It could also be one, one, one, but it turns out it's optimal to have a tree of radix four. The total amount of work is log(n) and it's amortized over all users it's only a constant.

BB: So some users are paying more than others to redeem.

JR: Right, so one of the issues is it a balanced tree or not. It turns out that we're already talking logarithmic, so it's going to be pretty small, we're talking plus or minus one on the depth in the tree. You can pay a little bit more, true, but the other side is that users who want to redeem earlier subsidize the users that redeem later. Say I have a branch that ultimately yields a group of 4, but one of those 4 decides they really want to get their coins, well they subsidize the creation of the neighbors along their path. There's naturally a priority queue. You want the fee market in bitcoin to be a priority queue where you pay more to get confirmed faster. The redemption can be a lazy process where you do it whenever demand is low enough to justify your use case. I think unconfirmed funds are fall worse. The real benefit of that-- and this is really good for multiparty situations- is that these payouts can be lightning channels. So how am I going to get liquidity in this thing? You can immediately start routing it in the lightning network. You can bootstrap lightning channels a lot more easily because you're not time sensitive on the creation of the channel there as long as it's confirmed, if you are using OP\_CHECKTEMPLATEVERIFY.

waxwing: Can I interrupt? Let's dial back a little bit. I think we have jumped a few steps ahead. I want to make sure I understand the most basic concept. I think Max was asking something similar. Do I understand that the most basic concept of congestion control is that because with this covenant mechanism you're able to treat unconfrimed -- or chains of unconfirmed transactions as if they are settled so to speak? This distinction about confirmation and redemption is that-- the user or the receiver can treat the money as having been received even though it's not in a bitcoin block because ther'es a covenant.

<https://utxos.org/uses/scaling/>

JR: So we have a diagram here on the screen. So you see the normal transaction diagram, and then the congestion controlled payments. So you have a single output and then you can have some sort of tree of possible redemption paths underneath. I show here a little bit more advanced demo but just ignore the part to the right and imagine you go down with this radix 4 tree. What this diagram shows is that the different leafs of this transaction graph can be expanded at different times and in different blocks. So batched transactions are somewhat better than normal transactions, but congestion controlled transactions are even better. Max asked earlier, how do they actually redeem? You can redeem on different kinds of trees. You can do a tree expansion. It's less fair if you're the one person that wants to redeem, then you have to pay for everyone, in certain designs of the tree. But another design fixes that.

MF: Someone is asking, how is this different from Child-Pays-for-Parent?

JR: The difference between this and CPFP is that CPFP is a non-consensus rule around which transactions can get in. In this world, you want to use CPFP where you can attach your spending transaction with a higher fee up the chain. If you see these bottom things, you would spend from one of these outputs and it would subsidize the chain of unconfirms. It's a distinct concept from CPFP because these pending transactions are already confirmed. There's no requirement to do CPFP to get confirmation of the parent. That's the difference.

JR: I'll probably remove CPFP or rearchitect it. The mempool is a big project right now. A lot of things don't work the way people think it works. Transaction pinning is one of those things that come up, and it's something a result from the CPFP policy. There's fixes, features and problems we end up having.

Q: ....

JR: You just spend from the child, and then it's CPFP. But that's where mempool issues come in. People have ..... perfect economic rationality is a NP-hard problem. We will never have a perfectly rational mempool, we will always reject some things. CPFP policy as written right now is really inefficient and it only works in a handful of cases, and it doesn't work for the lightning network even with the recent carve-out. It doesn't work properly for that.

SH: Is there any consideration to how exactly you structure the tree with radix 4? Is there any way to know-- how do I phrase this question? I guess, is there a certain algorithm or protocol that you do to place certain outputs in certain positions of the tree, or is it left to random, or left to whatever implementation?

JR: That's a great question. It's open to implementation. The bip119 opcode is generic. Perhaps you have prioritization or priority group. You can choose to have neutral priority where you try to pair high priority and low priority. Or a fair arrangement is high priority with other high priority where people can share fees. You can also do huffman encoding of the tree. Another one that I really like, and this goes into the lightning side of things which is a bit more advanced, is that you can order things by the probability of people being able to cooperate. If you have some notion of who knows other people, you can do a recursive multiparty lightning channel tree, and with a likelihood of working together, then you can make an optimal updateable tree state. This is a payment pool option. The last one is that, if you're making payments out and they might be the same service, you can make a payment tree where the keys that you suspect are owned by the same wallet, exist in the same subbranches and then there's an opportunity for cutting out some of the redemption transactions just by redeeming at that higher order node.

SH: My next question was about the probabilistic payouts in lightning, so thank you for answering that.

<https://diyhpl.us/wiki/transcripts/ctv-bip-review-workshop/>

BM: For CPFP, the other way to describe this is that the receiver can pull - and pay fees. What about the interplay between those two?

JR: CPFP is not the only way to pay fees. There's a litany of ways to pay fees in one of these systems. CPFP is I would just say the best way. It's a pure API where you want to declare which transactions you want to do, and then paying the fees for those should be abstracted away from the actual execution. CPFP is kind of good, just being able to express these arbitrary relationships. There are better APIs, though. I'm looking at another fork we could do, which is something that could give us more better fee subsidizing methodology. Can you repeat what the meat of the question is?

BM: If the receiver wants to pull a payment out of the tree and get it confirmed for whatever reason, then he may have to pay fees. The end transaction in the tree might pay fees, and the receiver might add more fees, or they might do replacement.

BB: I thought it would be paying fees in addition to whatever you pull out of the tree.

JR:  .... if you have things like ANYPREVOUT, then you would be able to get around some of the constraints. The reason why I prefer CPFP is that it doesn't disturb the txids in your parents and in your own branch. So I think txid stability is at least for the current lightning network design that we have, an important property. You can use replace-by-fee, sure, it just changes your txid. There's even, with OP\_CHECKTEMPLATEVERIFY, there's two forms of it. There's an unbounded form where you allow any output to be added that adds more money. There's also a bounded form that is possible- sort of like through a little quirk- but I like that you can do it-- where using a p2wsh segwit address, you can specify which key is allowed to add a dynamic amount of fee. If you pick a key that is known to be of the parties in that subtree, then it would only be through the coordination of those entities that the txid could be changed. If you're trying to do a lightning thing and the replace-by-fee requires coordination of all the sub-owners then it can work in a protected form that protects the state of the HTLCs but I think that's a complicated thing to work out, and I think CPFP is conceptually simpler. Replace-by-fee does not work well for a lot of services. This was one of the debates around replace-by-fee. People wanted to issue just one txid and they wanted to be an exchange and say here's your txid, and not have to double spend it... chains of transactions spending unconfirmed can get upset. Replace-by-fee is not awful that the code supports it, but I think it's an awful thing to use in practice because it has bad externalities. I think it's more robust to use CPFP, which is why I have been advocating CPFP.

MF: Jeremy, could you explain what OP\_CHECKTEMPLATEVERIFY is in comparison to some of the other covenant designs?

JR: Yeah. OP\_CHECKTEMPLATEVERIFY -- people look at the presentation I gave in 2017 and I said, covenants are really cool and let me think about what the whole space of covenants are. the Emin 2016 paper only covered one kind of covenant about an output and how it has to spend-- it doesn't cover details about what other inputs you have to be spent with. There's a lot of issues. I thought about it, I figured this is cool, I tried to get people excited, and at the implementation point people said well this stuff is kind of scary. We're not sure what's possible to do safely in bitcoin and we have properties we want to preserve around how transactions behave in reorgs.... so I said, okay, let's do a long study of how this stuff should work. I was doing this while working on other things, trying to figure out what makes sense. A lot of covenant proposals have flaws about how much computation they are expecting a validator to do, or the abstractions and boundaries that they violate in terms of transaction validation context like observing things you're not supposed to observe.

JR: As I went by, I started building vaults in like 2016. I was talking with some people about building it. I had a design that ended up being similar to what re-vault looks like. I was using lots of features like special sighash flags for making some of this work. But at the end of the day, it wasn't working that well. I went back to the drawing board-- how could we do big multiparty ECDSA signatures to emulate the big pre-signed chains? I tried to get people excited about this at one of the big Bitcoin Core dev meetings and they said nah not interested. Well, I was trying to accomplish a specific goal. What's the most conservative minimal opcode that I could introduce that could do this, without having any major security impact or change to bitcoin?

JR: So I came up with OP\_CHECKTEMPLATEVERIFY and it had a few precursors. It was more conservative originally, I have actually made it more flexible in this iteration and I presented that to the San Francisco Bitcoin Developers meetup. The response was positive- they said it doesn't have that much complexity for validation, and does not have much potential for a viral contamination or contagion. The design of OP\_CHECKTEMPLATEVERIFY ... Yes, it used to be called CHECKOUTPUTSHASHVERIFY and SECURETHEBAG. It was a back and forth. I wanted to give it a boring name, but then everyone at the meetup said that name sucks. Then I called it OP\_SECURETHEBAG and then people said bitcoin is serious business so CHECKTEMPLATEVERIFY is like a half-way point between something boring and something not quite boring.

JR: What you're doing is here's a specific transaction template. A template is everything except for the specific coutpoints or specific coins you're spending. This covers sequencing, version, locktime, scriptsigs, and outputs of course, and a few other fields in the txid commitment. Spencer, people are writing in the chat they want to bring back SECURETHEBAG. If you want to do that, you can, but I can't be responsible for it. It just checks that the transaction hash matches those details. That's basically it. That's why it's a template. It's the specific transaction you want to do. If you want to do more than one transaction-- well, wrap it in an IF ELSE.

BB: (ROLL/SWAP instead)

JR: There's a lot of funny script paradigms you can do with this stuff to make it easier to implement. The IF ELSE stuff always bothered me: do you do a big tree? Or a balanced tree? There's a script that Bryan is referencing where you just pass in the number of the branch you want to take, and then it's that simple. Bryan, maybe I'll send it to you for review. I posted on stackoverflow a script that emulates a switch statement. It's a little more verbose it's very easy for a compiler writer to target.

waxwing: Just want some clarification. Maybe I should be reading the docs. You said OP\_CHECKTEMPLATEVERIFY is essentially looking at what the txid encompasses-- in other words, the template transaction. But then you said it includes the scriptsig and not the coutpoints? Surely it's the other way around?

JR: It includes everything that... Okay, so one critique that comes up that people say I have designed OP\_CHECKTEMPLATEVERIFY for a very specific use case and there's a more general thing out there that can maybe be better. That's maybe a little true. The specific use case I have in mind is where you have a single input and there's a reason for that. If you have a single input, then there's no malleability you can have with the transaction if you know the parent's one coutpoint. You can go down the tree, fill in the details, and it's all deterministic. It's not that it's specifically designed for that, but it's specifically designed for that use case to work really well. When you look at the scriptsigs, that means you can't use bare script for OP\_CHECKTEMPLATEVERIFY because you're committing to signatures there if you have signatures. If you have a bare OP\_CHECKTEMPLATEVERIFY where it's just OP\_CHECKTEMPLATEVERIFY then you can use a bare script because you don't put anything in your scriptsig. As soon as you put in signatures, you have a hash cycle. In a segwit address, the ... your signatures are safe because it's not committed to; well you commit to the program in P2WSH which is a cool hack. That's why you commit to the scriptsig but not the... the scriptsigs impact the txid, but given a known chain of OP\_CHECKTEMPLATEVERIFY then the... given a single parent known coutpoint.

waxwing: I'll have to think about that, thanks.

JR: One of the big benefits of OP\_CHECKTEMPLATEVERIFY is all these non-interactive protocols. Here's an address, and if enough coins move into this address, then I have started a lightning channel-- without having to do any back-and-forth with my counterparty. In order to update that channel state, I need to know the txid of that channel that eventually gets created. If I spend to create that to that address, and it has a single input, then I know who spent to it, and I can fill out the txids below and any terminal state that I am updating with an HTLC is guaranteed to be stable. If I had malleability of the txid either by replace-by-fee or having multiple inputs or not committing to the set of data I commit to, then you run into the issue I was describing where things could get disrupted. It's a little bit extract but if you read the BIP there's a lot of language explaining why it was setup that way.

SH: I think you touched on this earlier. This might be a little off-topic. I think you touched on it during your OP\_CHECKTEMPLATEVERIFY workshop in February. How does tapscript some of the scripts you and Bryan mentioned just a few minutes ago or just OP\_CHECKTEMPLATEVERIFY scripts in general?

JR: Tapscript makes a lot of this stuff much easier. It makes this compilation about worrying about having... in tapscript, you never use an OP\_IF, well there's some use cases because you have a combinatorial blow up in script complexity where you would use it. But you wouldn't need to use it in most use cases. Tapscript makes a lot of these things easier to do. You could have an opcode which is an intermediate output or this transaction can't be included. That would give you the same functionality with OP\_CHECKTEMPLATEVERIFY. It's about just being able to have some branch that has to execute and you don't need to pass in all these bytes to signify which branch you want to execute which is just painful if you want to do that.

BM: What about arguments for or against OP\_CHECKTEMPLATEVERIFY in particular? There's a balance between a super restrictive opcode.... one of the things I have been looking at lately is Simplicity. If we soft-forked that into bitcoin, it has bare access to all transaction data and you could compose any covenant you want. It's the polar opposite in flexibility. I was thinking about implementing OP\_CHECKTEMPLATEVERIFY in Simplicity just to see how it works. What is too restrictive and why?

JR: Simplicity is really cool. I don't think it does what you think it does. You can write a valid contract in Simplicity for whatever covenant you want, but it's not necessarily executable on-chain. As you write more complex scripts in Simplicity, the runtime goes up, and there's some runtime limits. Unless you get a Simplicity jet for the specific one you want to add, you can't do it. So what if we had the optimal language for our sighash flags? Simplicity lets you define whatever you want, but then you can soft-fork in compatibility so that old clients are able to understand the new sspecification. Simplificty lets you express these things, but it doesn't let you make transactions based on them necessarily. One point that I would also make about the compactness-- and this is something that I have talked with Bram Cohen about and you can ask him about his actual opinion in case I misstate it... Even if you have a sophisticated covenant system, covenants are runtime compiled. A general covenant is runtime compiled where you're interpreting and doing whatever live in the script. OP\_CHECKTEMPLATEVERIFY is ahead-of-time compile and you only have to put on the chain the branches that you're actually doing. You can write that in Simplicity too, and then you might end up implementing OP\_CHECKTEMPLATEVERIFY in Simplicity... and I don't think we should ignore something that works today for this kind of use case. So if you just want to map it, maybe a jet for a OP\_CHECKTEMPLATEVERIFY type script and make it available in Simplicity one day. Having this-- it's both good for privacy in that you don't reveal your whole contract, but it's also good for compactness because you only reveal the part that you want to execute. There's some benefits to having the complete program expressed in simplicity.

JR: With regards to the question about why have something restrictive or general, it's really easy to audit what happens with OP\_CHECKTEMPLATEVERIFY. There's a few different codepaths. It's about 100 lines to add into Bitcoin Core. It's pretty easy. There's not... within an individual transaction, context, there's no major validation overhead. It makes it easy to write tools around it. Writing tools around Simplicity scripts is going to be complex because you're going to be working with arbitrary binaries and a few trusted primitives. But OP\_CHECKTEMPLATEVERIFY is already one such primitive. I think Bryan can speak to that.

JR: The original restrictions I had were around whether or not if you added other features to bitcoin if OP\_CHECKTEMPLATEVERIFY would allow you to do more complex scripts. I removed those features. People said-- well, we want these things to be enabled. I didn't want OP\_CHECKTEMPLATEVERIFY to occupy the space where we add it and then we can't add this other thing without enabling these very complex contracts. But people said, no, if we do add those things, like OP\_CAT then chances are we really do want to use that. So I said okay I'll remove the restrictions and make it more flexible. Now if you were to get OP\_CAT or OP\_SHA256STREAM in Bitcoin Core then you would be able to do much more sophisticated OP\_CHECKTEMPLATEVERIFY scripts. This gets to a separate question. One thing you could do is write a contract that says this template must pay out to all of these outputs and any output of your chosing. .... Why not just do ANYPREVOUT which gives you an analog for OP\_CHECKTEMPLATEVERIFY ? Well there would be no upgrade path for ANYPREVOUT short of Simplicity that would allow ANYPREVOUT to gain any higher-order templating facilities. So OP\_CHECKTEMPLATEVERIFY has a nice upgrade path available.

MF: Let's move on to vaults at some point. That's the other part of the discussion. We'll go with nothingmuch now. Are you there nothingmuch? I'll give you five seconds.

nothingmuch: What about recursion?

JR: nothingmuch asks about recursion. So basically, all the recursion happens at compile time. You can recurse as much as you want. This is sort of underwraps right now but I'm happy to describe it. I'm building a compiler for OP\_CHECKTEMPLATEVERIFY and I'm hoping to release it sometime soon. The compiler is Turing complete where you can compile any contract that expresses anything... but the compiler expresses a fixed set of transactions that can be produced. If you want any recursion you can do that at compile time, but not at the actual runtime. I don't know what "bounded input size" means, but I think that's a sufficient answer. We can follow-up offline about "bounded input size".

MF: Before we transition to vaults, one thing is-- in that 2017 presentation you talked about some of the grave concerns. Were you able to meet all those concerns? Fungibility, privacy, combinatorial explosion, I don't know if you have the transcript of that talk. Were you able to address those concerns?

JR: I don't think there are--- in terms of, so computational explosion. I think we're completely fine. Like I mentioned, compile time can be Turing complete but that's basically saying you on your own computer can run whatever you want and emit any transactions that you want. At runtime, it has to be a finite list of transactions. In terms of fungibility and privacy, I think it's relatively okay. If you want privacy, there are ways of getting it in a different trust model. If you want privacy, and you want a multisig signing server, then you can use taproot and you get a trust model where the signing server can steal your funds if you have all the parties working together. But they can't go offline and steal your funds because you have an alternative redemption path. In terms of fungibility, the issue is less around whether or not people can tag your coins because that's the privacy issue. The fungibility issue is whether your coin can be spent with other coins. Since this is a program that is guaranteed to terminate in an unencumbered coin, then those coins can be spent with any other coins. There's no ongoing recursive segregation of coins, so the fungibility issue is addressed. For privacy, I think having on-chain contracts--- these are good on-chain contracts and you don't learn other branches of the program there. But you do see that you're executing a OP\_CHECKTEMPLATEVERIFY program so this is a small privacy loss but this is going to enable a lot better layer 2 protocols and things like payjoin and mixers. It's going to make a lot of those things more efficient. Our ability to add better privacy tools to bitcoin is going to improve because we're able to bootstrap the protocol more efficiently. There's some new information revealed on-chain with OP\_CHECKTEMPLATEVERIFY, though.

MF: Let's go on to use cases. We've already discussed congestion control. Jeremy, what about the utxos.org site and go to the use cases tab.... So one of them is vaults, you have a bunch of other use cases there. Before we move on specifically to vaults, perhaps you can talk about some of the other promising use cases or which ones you are focusing on?

JR: I've been working on a compiler for OP\_CHECKTEMPLATEVERIFY and the use cases that I have now is triple of what's on this website. There's a lot you can do. Discreet log contracts, for example, all these things become much simpler to implement in this framework. I am really excited about non-interactive channels. That's going to be huge. It gets rid of 25-50% of the code base for implementing a lightning channel because a lot of it is the initial handshaking. The other stuff is related with like scaling, trustless coordination mining pools where you can pay people out... I sent Bob some drafts around this at some point. You can setup a mining pool where every block it pays out to ... over the last 1000 blocks and you can do this on a running basis where there's no central operator, you can only participate if you provably pay out to the people in the last 1000 block run, and you can use the payment channels so that you make the average number of redemptions for miners is on average 1. You can minimize the amount of on-chain load and being completely trustless for those mines in receiving the redemptions. This makes bitcoin a really good base layer for layer 2, which is something that I think is going to be the major use case. Vaults are also interesting not just for institutions but also people thinking about their estate and inheritance for their last will and testament. This is where non-interactivity is important: say you setup an auditable vault system that pays out a trust fund to all your inheritors without having to inform them about what the layout is. It can also be proved to an auditor which is important for tax considerations. Say you gave $10m to your heirs, well you have to prove when they got access to those funds. I think vaults are an important use case, not just for individual businesses, but I think vaults are most impactful for end-users where you don't have the resources to employee people to be managing this for you. Say you have an offline wallet that you can send money to, and funds automatically come back online to your phone, but if you ever lose the phone you can stop the flow. That's exciting for OP\_CHECKTEMPLATEVERIFY in particular- it's the ability to send funds to a vault address, which automatically moves funds to your hot wallet. Say you have keys in a wallet that are only used in the event of a disaster, in 7 different bank vaults around the world. You don't have a requirement to ever have the recover ykeys, unless you need to recover. That's the big difference from OP\_CHECKTEMPLATEVERIFY and vaults: you remove the keys from the hot path. There's no need for signing, just sending funds to the current place. By the way, this vault diagram is not accurate. This is a type of vault. The ones I implemented in the repo are more similar to the form that Bryan put out in his python-vaults prototype.

MF: I am assuming you are going to have to focus on one or two use cases. You need to convince people of the use case, and then make sure it doesn't add anything to the protocol.

JR: It's been difficult being a singular advocate for OP\_CHECKTEMPLATEVERIFY because you have to make a lot of conflicting arguments that ultimately work together. If you just told one side or the other side, they wonder. Bob gives me a little bit of grief: if you have to design an opcode specifically the best thing for vaults, and my opinion is yes and then the question is, well it does all this other stuff too--- and the other side of the fence is that, well OP\_CHECKTEMPLATEVERIFY you only have a single use case you care about. Can you show 100 use cases because we want flexibility? Yes, it's general. I'm building this language out... I'm hoping to show yes it's flexible and yes it's really good for these use cases and hopefully this will be available soon. The other difficult thing is talking about fees with scaling, and I'm telling users that this will decrease fees but it will also increase mining revenue - so how? Well, it's layer 2 related. You're going to get more users. It's Jarven's paradox: as the system becomes more useful, the performance goes up.

....

MF: We'll move on to vaults. Some vaults need OP\_CHECKTEMPLATEVERIFY and others don't. I think Kevin's re-vault doesn't require it but he's willing to use it. In terms of the resources we have on this pastebin, is an early post from Bob McElrath about re-imagining cold storage with timelocks.

BM: I can give a brief description. This was published shorlty after Gun Sirer et al 2016 published. It was around the same time timelocks came out. At the time, before Jeremy introduced OP\_CHECKTEMPLATEVERIFY -- there was no covenant mechanism at the time. There were about 5 proposals that were covered in the Munich talk I gave. The only thing that was available was secure key deletion. In the old west, people would create a bank vault with a physical timelock. The bank operator goes home, they lock the vault such that a robber can't get int oa vault. This is a physical example of a timelock. At the time, timelocks had just come out and enabled these use cases. The picture for the vault use case is two spending branches: one is timelock and one of which is not. Your timelock branch is the usual operation. This is opposite to how lightning works. You want to enforce a timelock on your funds such that you can't spend it. There is an un-vault operation where you take your funds and you have to unvault them. In the case of OP\_CHECKTEMPLATEVERIFY you're broadcasting a redemption transaction, or in secure key deletion you broadcast a transaction, and re-vault does a tree and pre-sign this transaction. In my blog post, once you sign the transaction, it's a vaulted object. Now you have to figure out how to move it around, when to move it, when to broadcast it. This signed transaction is somewhat lower risk than bare private keys. There's two spending paths- one is timelocked, but another has a different set of keys. That's the emergency backup condition.

BB: You should have a pre-signed push transaction to cold storage, instead of going to the cold storage keys.

BM: I call that a push-to-recovery transaction. Well now I have three sets of keys. I have my spending key, my emergency backup key, and I have to have somewhere to send those funds if I have to use the emergency backup keys. These vault designs end up rather complicated rathe rfast. I am talking about at least three wallets and a few devices. When a thief gets in and tries to steal funds, well who pushes the transaction? This implies a set of watchtowers similar to lightning watchtowers that watch for this event and are tasked with broadcasting a push transaction that sends to a super backup wallet.

BB: (sharding)

MF: There's some different designs here. Are there certain frameworks that we can hang the different designs on? I know there's Bryan's post-- we'll get to that, Bob has one design, and Kevin has another design. How do I structure this inside my head?

JR: The way that I have been thinking about it is in terms of what the base layer components are. I think that in a vault essentially what you're looking at is annuity.  You're setting up a fixed contract that has some timing conditions on next payments. At the base layer of most good vault designs, there is something you would do different, this is what you're working with. The value flows along that path.

....

KL: We're far from having a blockchain-enforced covenant. So we have to use some tricks around it, like secure key deletion, or we use co-signing servers in re-vault which are far from being perfect. At least we can somewhat emulate the fact that the output is pre-defined.

....






OP\_CHECKTEMPLATEVERIFY


